<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>

<head>
<title> Niall L. Williams </title>

<!--<link rel="stylesheet" type="text/css" href="stylesheet.css">-->
 
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<meta http-equiv="Content-Style-Type" content="text/css">
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
<meta name="robots" content="index,follow">
<meta name="description" content="Niall Williams' homepage">
<meta name="keywords" content="Niall, Williams, University of Maryland, College Park, virtual reality, VR, motion planning, human perception, computer graphics">

<link rel="stylesheet" type="text/css" media="screen, projection" href="stylesheet.css">
<link rel="icon" type="image/png" href="img/favicon-16x16.png">
<script src="https://kit.fontawesome.com/db27faa69c.js" crossorigin="anonymous"></script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<script src="js/img_hover.js"></script>

</head>
<body>

	<div id="main">
		<div id="contact">
			<table border=0><tr>
				<!-- <td width ="400" align=center valign=bottom> <img class="imageHeader" id="me" src="img/profile.png" alt="Niall Williams" border=0 width="245"> -->
				<!-- <td width ="400" align=center valign=bottom> <img class="imageHeader" id="me" src="img/profile.png" alt="Niall Williams" border=0 width="245"> -->
				<!-- <td width ="400" align=center valign=bottom> <img class="imageHeader" id="me" src='img/profile.png' onmouseover="this.src='img/profile-fun1.png';" onmouseout="this.src='img/profile.png';" alt="Niall Williams" border=0 width="245"/> -->

				<td width ="400" align=center valign=bottom> <img class="imageHeader" id="me" src='img/profile.png' onmouseover="getRandomImage()" onmouseout="this.src='img/profile.png';" alt="Niall Williams" border=0 width="245"/>
				<td width="450">
					<h2>Niall L. Williams</h2>
					<p>
						Faculty Fellow & Postdoc<br>
						<a href="https://www.immersivecomputinglab.org/" target="_blank">Immersive Computing Lab</a><br>
						<a href="https://engineering.nyu.edu/" target="_blank">Tandon Computer Science & Engineering</a><br>
						<a href="https://www.nyu.edu/" target="_blank">New York University</a><br>
						Brooklyn, NY 11201<br>
						USA <br>
					</p>

					<table border=0 cellpadding=0 cellspacing=0><tr>
						<td>e-mail: <b>n.williams</b> AT <b>nyu.edu</b></td>
						</tr><tr>
						
						<td> [<a href="cv.pdf" target="_blank">CV</a>] 
							[<a href="https://scholar.google.com/citations?user=KIUsT1cAAAAJ"><i class="fa fa-fw fa-google"></i>Google Scholar</a>] 
							[<a href="https://bsky.app/profile/niallw.bsky.social"><i class="fa fa-fw fa-bluesky"></i> target="_blank">Bluesky</a>] 
							[<a href="https://www.linkedin.com/in/niall-l-williams-262702137/"><i class="fa fa-fw fa-linkedin"></i> target="_blank">LinkedIn</a>] 
							[<a href="https://orcid.org/0000-0002-0273-883X"><i class="fa fa-fw fa-orcid"></i> target="_blank">ORCiD</a>]</td>
						</tr><tr></tr>
					</table>
					<p style="margin-bottom:0.5cm;">
					</p>
				</td></tr>
			</table>
		</div> <br>

	<hr>

		<p class="mainlinks">
			[<a href="#aboutme">About Me</a>]
			[<a href="#news">News</a>]
			[<a href="#publications">Publications</a>]
			[<a href="#service">Service</a>]
			[<a href="#teaching">Teaching</a>]
			[<a href="#fun_stuff">Fun Stuff</a>]
		</p>

	<hr>

	<div id="aboutMe"><a name="aboutme"></a>

		</br>
		<!-- <div style="font-weight: bold; padding: 0.5em; text-align: center; border: solid coral; border-width: 0.25em; background-color: #FBD603;">I am on the job market for a full-time position starting in Summer or Fall 2024! I am interested in positions relating to AR/VR, human perception, and computer graphics. Please <a href = "mailto: niallw@umd.edu">contact me</a> if you have any leads!</div> -->

		<h2>About me</h2>
		<p>I am a <a href="https://engineering.nyu.edu/news/new-faculty-fall-2024#fellows" target="_blank">Faculty Fellow</a> at the New York University Tandon School of Engineering. I am part of the <a href="https://www.immersivecomputinglab.org/" target="_blank">Immserive Computing Lab</a>, where I work with <a href="https://qisun.me/" target="_blank">Prof. Qi Sun</a> on applied human perception for computer graphics.
		</p>
		<p>I completed a PhD in Computer Science at the University of Maryland, College Park, where I was a member of the <a href="https://gamma.umd.edu/" target="_blank">GAMMA lab</a>. My PhD was under the supervision of <a href="https://www.cs.umd.edu/people/dmanocha" target="_blank">Prof. Dinesh Manocha</a>, <a href="https://www.cs.purdue.edu/homes/ab/" target="_blank">Prof. Aniket Bera</a>, and <a href="https://www.cs.umd.edu/~lin/" target="_blank">Prof. Ming C. Lin</a>. My dissertation focused on computation methods for natural walking in virtual reality. To this end, I used techniques from visual perception, robot motion planning, computational geometry, and statistical modeling to develop rigorous algorithms for steering users through unseen physical environments. My dissertation is titled <a href="pdfs/publications/williams2024dissertation.pdf" target="_blank">"Computational Methods for Natural Walking in Virtual Reality."</a>
		</p>
		<p>
		I graduated with a B.S. with High Honors in Computer Science from <a href="https://www.davidson.edu/" target="_blank">Davidson College</a>. During my time at Davidson, I was a member of the DRIVE lab, where I was advised by <a href="https://www.davidson.edu/people/tabitha-peck" target="_blank">Prof. Tabitha C. Peck</a>. My undergraduate thesis studied redirected walking thresholds under different conditions and how we can efficiently estimate them.
		</p>
		<p>
		My name is pronounced in the same way that you pronounce "Nile."<br>
		In my free time, I enjoy bouldering and competitive video games (DotA 2 and Tetris).
		</p>
	</div>

	<hr>

	<!-- ***************************************************************************** -->
	<!-- ***************************************************************************** -->
	<!-- ******************************** NEWS *************************************** -->
	<!-- ***************************************************************************** -->
	<!-- ***************************************************************************** -->
	<div id="news"><a name="news"></a>
		<h2>News</h2>
		<ul>
		<!-- <li><b>month year</b>: xxx_news_xxx</li> -->
		<li><b>December 2024</b>: One <a href="project_pages/williams2025sensitivity.html">TVCG paper</a> accepted to IEEE VR 2025!</li>
		<li><b>September 2024</b>: Joined NYU Tandon CSE as a <a href="https://engineering.nyu.edu/news/new-faculty-fall-2024#Niall">Faculty Fellow</a> & postdoc in the <a href="https://www.immersivecomputinglab.org/">Immersive Computing Lab</a> with <a href="https://qisun.me/">Prof. Qi Sun!</a></li>
		<li><b>August 2024</b>: <a href="https://x.com/gammaumd/status/1828838553209712912">Successfully defended my PhD!</a></li>
		<li><b>June 2024</b>: <a href="https://www.snexplores.org/article/computer-scientist-safer-virtual-reality">I was featured in the June volume of Science News Explores, a science magazine for kids!</a></li>
		<li><b>May 2024</b>: Returned to the Human Performance and Experience team at NVIDIA Research for a second internship!</li>
		<li><a href="news.html">All news...</a></li>
		</ul>
	</div>

	<hr>

	<!-- ***************************************************************************** -->
	<!-- ***************************************************************************** -->
	<!-- ******************************** PUBLICATIONS ******************************* -->
	<!-- ***************************************************************************** -->
	<!-- ***************************************************************************** -->
	<div id="publications"><a name="publications"></a>
		<h2>Journal and Conference Publications</h2>
		<table border=0 cellspacing=15 cellpadding=10 width="100%">
		A full list of my publications can also be found on my <a href="https://scholar.google.com/citations?user=KIUsT1cAAAAJ" target="_blank">Google Scholar</a> profile.
		Representative papers are <span class="highlight">highlighted</span>.<br>
		* denotes equal contributions.

        <!-- <tr>
			<td width="250">
			<a href="pdfs/publications/XXX_PAPER.pdf"><img class="image" src="img/teasers/XXX_TEASER.png" alt="XXX_ALT_TEXT" border=0 width="250"></a>
			</td><td>
            <b>XXX_TITLE</b><br>
            XXX_AUTHORS<br>
			<i>XXX_VENUE</i>, XXX_YEAR
			<p class="links">
            [<a href="pdfs/publications/XXX_PAPER.pdf">Paper</a>]
            [<a href="XXX_ARXIV">arXiv</a>]
            [<a href="XXX_PROJECT_PAGE">Project Page</a>]
            [<a href="XXX_VIDEO">Video</a>]
            [<a href="XXX_CODE">Code</a>]
            [<a href="XXX_BIBTEX">Bibtex</a>]
			</p>
			<br>
			XXX_SUMMARY
			</td>
			</tr> -->

			<tr>
			<td width="250">
			<a href="pdfs/publications/williams2025sensitivity.pdf"><img class="image" src="img/teasers/williams2025sensitivity.png" alt="Visualizations of the effects of increased rotation gains on a user's physiological signals (gaze and postural stability)." border=0 width="250"></a>
			</td><td style="background-color:#ffffd0">
            <b>Sensitivity to Redirected Walking Considering Gaze, Posture, and Luminance</b><br>
            <strong>Niall L. Williams</strong>, <a href="https://loganstevens.github.io/">Logan C. Stevens</a>, <a href="https://www.cs.purdue.edu/homes/ab/">Aniket Bera</a>, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a><br>
			<i>Transactions on Visualization and Computer Graphics</i>, 2025 <br>
			<i>Proc. IEEE VR 2025</i>
			<p class="links">
            [<a href="pdfs/publications/williams2025sensitivity.pdf">Paper</a>]
            [<a href="https://arxiv.org/abs/2503.15505">arXiv</a>]
            [<a href="project_pages/williams2025sensitivity.html">Project Page</a>]
            [<a href="">Video coming soon!</a>]
            <!-- [<a href="XXX_CODE">Code</a>] -->
            [<a href="bib/williams2025sensitivity.txt">Bibtex</a>]
			</p>
			<br>
			We measured users' sensitivity to rotation gains in photopic and mesopic luminance conditions and measured the correlations between rotation gains and physiological signals (gaze and posture data).
			</td>
			</tr>

			<tr>
			<td width="250">
			<a href="pdfs/publications/saeedpour2024perceptual.pdf"><img class="image" src="img/teasers/saeedpour2024perceptual.png" alt="A picture of the custom-built head-mounted display simulator used in our experiment." border=0 width="250"></a>
			</td><td style="background-color:#ffffd0">
            <b>Perceptual Thresholds for Radial Optic Flow Distortion in Near-Eye Stereoscopic Displays</b><br>
            Mohammad R. Saeedpour-Parizi, <strong>Niall L. Williams</strong>, Tim Wong, Phillip Guan, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a>, Ian M. Erkelens<br>
			<i>Transactions on Visualization and Computer Graphics</i>, 2024 <br>
			<i>Proc. IEEE VR 2024</i>
			<p class="links">
			[<a href="pdfs/publications/saeedpour2024perceptual.pdf">Paper</a>]
            [<a href="https://arxiv.org/abs/2402.07916">arXiv</a>]
			[<a href="https://gamma.umd.edu/ROF/">Project Page</a>]
            [<a href="">Video coming soon</a>]
			[<a href="bib/saeedpour2024perceptual.txt">Bibtex</a>]
			[<a href="https://doi.org/10.1109/TVCG.2024.3372075">DOI</a>]
			</p>
			<br>
			We measured how sensitive observers are to image magnification artifacts in near-eye displays and to what extent we can leverage blinks to decrease their visual sensitivity, with applications to mitigating the vergence-accommodation conflict.
			</td>
			</tr>

			<tr> 
			<td width="250">
			<a href="pdfs/publications/williams2023active_haptic.pdf"><img class="image" src="img/teasers/williams2023active_haptic2.png" alt="Visualization of how we use active haptic feedback to improve the user's virtual experience." border=0 width="250"></a>
			</td><td style="background-color:#ffffd0">
			<b>A Framework for Active Haptic Guidance Using Robotic Haptic Proxies</b><br>
			<strong>Niall L. Williams*</strong>, <a href="https://www.nickvr.me/">Nicholas Rewkowski*</a>, <a href="https://jsli.dev/">Jiasheng Li</a>, <a href="https://www.cs.umd.edu/~lin/">Ming C. Lin</a><br>
			<i>IEEE International Conference on Robotics and Automation (ICRA)</i>, 2023
			<p class="links">
			[<a href="pdfs/publications/williams2023active_haptic.pdf">Paper</a>]
			[<a href="https://arxiv.org/abs/2301.05311">arXiv</a>]
			[<a href="https://gamma.umd.edu/active_haptic_guidance/">Project Page</a>]
			[<a href="https://www.youtube.com/watch?v=DI2cGm7tlbE">Video</a>]
			<!-- [<a href="XXX_CODE">Code</a>] -->
			[<a href="bib/williams2023active_haptic.txt">Bibtex</a>]
			[<a href="https://doi.org/10.1109/ICRA48891.2023.10160996">DOI</a>]
			</p>
			<br>
			We used a robot to proactively generate context-aware haptic feedback that influences the user's behavior in mixed reality, to improve the immersion and safety of their virtual experience.
			</td>
			</tr>

			<tr>
			<td width="250">
			<a href="pdfs/publications/williams2022eni.pdf"><img class="image" src="img/teasers/williams2022eni.png" alt="Visualization of our navigability metric." border=0 width="250"></a>
			</td><td style="background-color:#ffffd0">
			<b>ENI: Quantifying Environment Compatibility for Natural Walking in Virtual Reality</b><br>
			<strong>Niall L. Williams</strong>, <a href="https://www.cs.purdue.edu/homes/ab/">Aniket Bera</a>, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a><br>
			<i> IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR)</i>, 2022 &nbsp <font color="red"><strong>[Best Paper Honorable Mention]</strong></font>
			<p class="links">
			[<a href="pdfs/publications/williams2022eni.pdf">Paper</a>]
			[<a href="https://arxiv.org/abs/2201.01261">arXiv</a>]
			[<a href="https://gamma.umd.edu/eni/">Project Page</a>]
			[<a href="https://www.youtube.com/watch?v=XcFQbl82yBw">Video</a>]
			[<a href="https://github.com/niallw/ENI">Code</a>]
			[<a href="bib/williams2022eni.txt">Bibtex</a>]
			[<a href="https://doi.org/10.1109/VR51125.2022.00061">DOI</a>]
			</p>
			<br>
			We provide a metric to quantify the ease of collision-free navigation in VR for any given pair of physical and virtual environments, using geometric features.
			</td>
			</tr>

			<tr>
			<td width="250">
			<a href="pdfs/publications/williams2021redirected.pdf"><img class="image" src="img/teasers/williams2021redirected.png" alt="Visibility polygons can represent free space." border=0 width="250"></a>
			</td><td style="background-color:#ffffd0">
			<b>Redirected Walking in Static and Dynamic Scenes Using Visibility Polygons</b><br>
			<strong>Niall L. Williams</strong>, <a href="https://www.cs.purdue.edu/homes/ab/">Aniket Bera</a>, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a><br>
			<i>Transactions on Visualization and Computer Graphics</i>, 2021 <br>
			<i>Proc. IEEE ISMAR 2021</i> &nbsp <font color="red"><strong>[Best Paper Honorable Mention]</strong></font>
			<p class="links">
			[<a href="pdfs/publications/williams2021redirected.pdf">Paper</a>]
			[<a href="https://arxiv.org/abs/2106.06807">arXiv</a>]
			[<a href="https://gamma.umd.edu/vis_poly/">Project Page</a>]
			[<a href="https://www.youtube.com/watch?v=lnDQn2qv0Qw">Video</a>]
			[<a href="https://github.com/pasumi/pasumi">Code</a>]
			[<a href="bib/williams2021redirected.txt">Bibtex</a>]
			[<a href="https://doi.org/10.1109/TVCG.2021.3106432">DOI</a>]
			</p>
			<br>
			We formalize the redirection problem using motion planning and use this formalization to develop an improved steering algorithm based on the similarity of physical and virtual free spaces.
			</td>
			</tr>

			<tr>
			<td width="250">
			<a href="pdfs/publications/williams2021arc.pdf"><img class="image" src="img/teasers/williams2021arc.png" alt="Our algorthim yields physical paths that match virtual paths." border=0 width="250"></a>
			</td><td style="background-color:#ffffd0">
			<b>ARC: Alignment-based Redirection Controller for Redirected Walking in Complex Environments</b><br>
			<strong>Niall L. Williams</strong>, <a href="https://www.cs.purdue.edu/homes/ab/">Aniket Bera</a>, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a><br>
			<i>Transactions on Visualization and Computer Graphics</i>, 2021 <br>
			<i>Proc. IEEE VR 2021</i> &nbsp <font color="red"><strong>[Best Paper Honorable Mention]</strong></font>
			<p class="links">
			[<a href="pdfs/publications/williams2021arc.pdf">Paper</a>]
			[<a href="https://arxiv.org/abs/2101.04912">arXiv</a>]
			[<a href="https://gamma.umd.edu/arc/">Project Page</a>]
			[<a href="https://www.youtube.com/watch?v=myz2Qnyaj7Q">Video</a>]
			[<a href="https://github.com/pasumi/pasumi">Code</a>]
			[<a href="bib/williams2021arc.txt">Bibtex</a>]
			[<a href="https://doi.org/10.1109/TVCG.2021.3067781">DOI</a>]
			</p>
			<br>
			We achieve improved steering results with redirected walking by steering the user towards positions in the physical world that more closely match their position in the virtual world.
			</td>
			</tr>

			<tr>
			<td width="250">
			<a href="pdfs/publications/terry2020petting.pdf"><img class="image" src="img/teasers/terry2020petting.png" alt="Logo for the PettingZoo library." border=0 width="250"></a>
			</td><td>
			<b>PettingZoo: Gym for Multi-Agent Reinforcement Learning</b><br>
			<a href="https://scholar.google.com/citations?user=gb83gcIAAAAJ&hl=en&oi=sra">J. K. Terry</a>, Benjamin Black, Mario Jayakumar, Ananth Hari, Ryan Sullivan, Luis Santos, Clemens Dieffendahl, <strong>Niall L. Williams</strong>, Yashas Lokesh, Caroline Horsch, Praveen Ravi<br>
			<i>Neural Information Processing Systems (NeurIPS)</i>, 2021
			<p class="links">
			[<a href="pdfs/publications/terry2020petting.pdf">Paper</a>]
			[<a href="https://pettingzoo.farama.org/index.html">Website</a>]
			[<a href="https://arxiv.org/abs/2009.14471">arXiv</a>]
			[<a href="https://github.com/PettingZoo-Team/PettingZoo">Code</a>]
			[<a href="bib/terry2020petting.txt">Bibtex</a>]
			</p>
			<br>
			One of the most popular libraries for multi-agent reinforcement learning.
			</td>
			</tr>

			<tr>
			<td width="250">
			<a href="pdfs/publications/bhattacharya2020generating.pdf"><img class="image" src="img/teasers/bhattacharya2020generating.png" alt="Our emotionally expressive agents in an AR environment." border=0 width="250"></a>
			</td><td>
			<b>Generating Emotive Gaits for Virtual Agents Using Affect-Based Autoregression</b><br>
			<a href="http://www.cs.umd.edu/~uttaranb/">Uttaran Bhattacharya</a>, <a href="https://www.nickvr.me/">Nicholas Rewkowski</a>, Pooja Guhan, <strong>Niall L. Williams</strong>, <a href="http://www.cs.umd.edu/~trisha/">Trisha Mittal</a>, <a href="https://www.cs.purdue.edu/homes/ab/">Aniket Bera</a>, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a><br>
			<i>IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</i>, 2020
			<p class="links">
			[<a href="pdfs/publications/bhattacharya2020generating.pdf">Paper</a>]
			[<a href="https://arxiv.org/abs/2010.01615">arXiv</a>]
			[<a href="https://gamma.umd.edu/researchdirections/affectivecomputing/affagents/gen_emotive_gaits/">Project Page</a>]
			[<a href="https://www.youtube.com/watch?v=wxkvW8CtHt0">Video</a>]
			[<a href="https://github.com/UttaranB127/GeneratingEmotiveGaits">Code</a>]
			[<a href="bib/bhattacharya2020generating.txt">Bibtex</a>]
			[<a href="https://doi.ieeecomputersociety.org/10.1109/ISMAR50242.2020.00020">DOI</a>]
			</p>
			<br>
			We automatically synthesize emotionally expressive gaits for virtual avatars using an autoregression network.
			</td>
			</tr>

			<tr>
			<td width="250">
			<a href="pdfs/publications/williams2019estimation.pdf"><img class="image" src="img/teasers/williams2019estimation.png" alt="Difference in viewports with a 40 and 110 FOV." border=0 width="250"></a>
			</td><td style="background-color:#ffffd0">
			<b>Estimation of Rotation Gain Thresholds Considering FOV, Gender, and Distractors</b><br>
			<strong>Niall L. Williams</strong>, <a href="https://www.davidson.edu/people/tabitha-peck">Tabitha C. Peck</a><br>
			<i>Transactions on Visualization and Computer Graphics</i>, 2019<br>
			<i>Proc. IEEE ISMAR 2019</i>
			<p class="links">
			[<a href="pdfs/publications/williams2019estimation.pdf">Paper</a>]
			[<a href="https://github.com/niallw/Redirected-Walking-Thresholds">Code</a>]
			[<a href="bib/williams2019estimation.txt">Bibtex</a>]
			[<a href="https://doi.org/10.1109/TVCG.2019.2932213">DOI</a>]
			</p>
			<br>
			We measured perceptual thresholds for redirected walking and found that the user's tolerance for redirection depends on the field of view, the presence of distractors, and their gender.
			</td>
			</tr>
		</table>


        <!-- ***************************************************************************** -->
        <!-- ***************************************************************************** -->
        <!-- ************************ WORKSHOP PAPERS & POSTERS ************************** -->
        <!-- ***************************************************************************** -->
        <!-- ***************************************************************************** -->
		<h2>Workshop Papers and Posters</h2>
		<table border=0 cellspacing=15 cellpadding=10 width="100%">
			<tr>
			<td width="250">
			<a href="pdfs/publications/rosenholtz2024who_you_lookin_at_poster.pdf"><img class="image" src="img/teasers/rosenholtz2024who_you_lookin_at_poster.png" alt="XXX_ALT_TEXT" border=0 width="250"></a>
			</td><td>
			<b>Who you lookin' at? Perception of gaze direction in group settings depends on naturalness of gaze behavior and clutter</b><br>
			<a href="https://research.nvidia.com/person/ruth-rosenholtz">Ruth Rosenholtz</a>, <strong>Niall L. Williams</strong><br>
			<i>Vision Sciences Society</i>, 2024
			<p class="links">
			[<a href="pdfs/publications/rosenholtz2024who_you_lookin_at_poster.pdf">Poster PDF</a>]
			[<a href="https://jov.arvojournals.org/article.aspx?articleid=2801797">JoV Abstract</a>]
			[<a href="bib/rosenholtz2024who.txt">Bibtex</a>]
			[<a href="https://doi.org/10.1167/jov.24.10.1295">DOI</a>]
			</p>
			<br>
			We measured how accurately people can judge the gaze direction of digital human avatars realistic, naturalistic scene with natural and unnatural body poses.
			</td>
			</tr>
			
			<tr>
			<td width="250">
			<a href="pdfs/publications/williams2021redirection_workshop.pdf"><img class="image" src="img/teasers/williams2021redirection_workshop.png" alt="XXX_ALT_TEXT" border=0 width="250"></a>
			</td><td>
			<b>Redirection Using Alignment</b><br>
			<strong>Niall L. Williams</strong>, <a href="https://www.cs.purdue.edu/homes/ab/">Aniket Bera</a>, <a href="https://www.cs.umd.edu/people/dmanocha">Dinesh Manocha</a><br>
			<i>IEEE VR Locomotion Workshop</i>, 2021
			<p class="links">
			[<a href="pdfs/publications/williams2021redirection_workshop.pdf">2-page Abstract</a>]
			[<a href="bib/williams2021redirection_workshop.txt">Bibtex</a>]
			</p>
			<br>
			We provide a general framework for how alignment can be used in redirected walking to steer the user towards similar physical and virtual positions.
			</td>
			</tr>

			<tr>
			<td width="250">
			<a href="pdfs/publications/qi2020augmenting.pdf"><img class="image" src="img/teasers/qi2020augmenting.png" alt="Our haptic interface and buouancy simulator." border=0 width="250"></a>
			</td><td>
			<b>Augmenting Physics Education with Haptic and Visual Feedback</b><br>
			Kern Qi, <a href="https://davidborland.github.io/webpage/">David Borland</a>, Emily Jackson, <strong>Niall L. Williams</strong>, <a href="https://ced.ncsu.edu/people/jminogu/">James Minogue</a>, and <a href="https://www.davidson.edu/people/tabitha-peck">Tabitha C. Peck</a><br>
			<i>IEEE VR 5th Workshop on K-12+ Embodied Learning through Virtual & Augmented Reality (KELVAR)</i>, 2020
			<p class="links">
			[<a href="pdfs/publications/qi2020augmenting.pdf">2-page Abstract</a>]
			[<a href="bib/qi2020augmenting.txt">Bibtex</a>]
			</p>
			<br>
			Using haptic force feedback to help teachers better understand physics concepts.
			</td>
			</tr>

			<tr>
			<td width="250">
			<a href="pdfs/publications/qi2020impact.pdf"><img class="image" src="img/teasers/qi2020impact.png" alt="Our haptic interface and experiment conditions." border=0 width="250"></a>
			</td><td>
			<b>The Impact of Haptic and Visual Feedback on Teaching</b><br>
			Kern Qi, <a href="https://davidborland.github.io/webpage/">David Borland</a>, Emily Jackson, <strong>Niall L. Williams</strong>, <a href="https://ced.ncsu.edu/people/jminogu/">James Minogue</a>, and <a href="https://www.davidson.edu/people/tabitha-peck">Tabitha C. Peck</a><br>
			<i>IEEE Conference on Virtual Reality and 3D User Interfaces</i>, 2020
			<p class="links">
			[<a href="pdfs/publications/qi2020impact.pdf">2-page Abstract</a>]
			[<a href="bib/qi2020impact.txt">Bibtex</a>]
			</p>
			</td>
			</tr>

			<tr>
			<td width="250">
			<a href="pdfs/publications/williams2019poster.pdf"><img class="image" src="img/teasers/williams2019poster.png" alt="Significant differences results." border=0 width="250"></a>
			</td><td>
			<b>Estimation of Rotation Gain Thresholds for Redirected Walking Considering FOV and Gender</b><br>
			<strong>Niall L. Williams</strong>, <a href="https://www.davidson.edu/people/tabitha-peck"></a>Tabitha C. Peck</a><br>
			<i>IEEE Conference on Virtual Reality and 3D User Interfaces</i>, 2019
			<p class="links">
			[<a href="pdfs/publications/williams2019poster.pdf">2-page Abstract</a>]
			[<a href="bib/williams2019estimation_poster.txt">Bibtex</a>]
			</p>
			</td>
			</tr>
		</table>

		<!-- ***************************************************************************** -->
		<!-- ***************************************************************************** -->
		<!-- ******************************** INVITED TALKS ****************************** -->
		<!-- ***************************************************************************** -->
		<!-- ***************************************************************************** -->
		<h2>Invited Talks</h2>
		<table border=0 cellspacing=15 cellpadding=10 width="100%">
			<tr>
			<td width="250">
			<a href="https://www.youtube.com/watch?v=SjIUjDS0ou8"><img class="image" src="img/teasers/siggraph_invited_talk_thumbnail.png" alt="Thumbnail for my SIGGRAPH talk." border=0 width="250"></a>
			</td><td>
			<b>ARC: Alignment-based Redirection Controller for Redirected Walking in Complex Environments</b><br>
			<strong>Niall L. Williams</strong><br>
			<i>SIGGRAPH TVCG Session on VR</i>, 2021
			<p class="links">
			[<a href="https://www.youtube.com/watch?v=SjIUjDS0ou8">Video</a>]
			</p>
			</td>
			</tr>
		</table>
	</div>

		<!-- ***************************************************************************** -->
		<!-- ***************************************************************************** -->
		<!-- ******************************** SERVICE ************************************ -->
		<!-- ***************************************************************************** -->
		<!-- ***************************************************************************** -->
		<div id="service"><a name="service"></a>
			<h2>Service</h2>
			<ul>
				<li><strong>Academic community</strong></li>
				<ul>
					<li><a href="https://research.siggraph.org/">SIGGRAPH Research Career Development Committee</a> <span style="float:right;">2021 - Present</span><br></li>
					<li>Peer reviewing: IEEE TVCG (2021 - present), IEEE VR (2020 - present), IEEE ISMAR (2021), IEEE Trans. on Games (2021), MobileHCI (2021), ACM CHI (2022)</li>
					<li>Student volunteer: IEEE VR (2020, 2021), IEEE ISMAR (2019)</li>
				</ul>
				<li><strong>University of Maryland, College Park</strong></li>
				<ul>
					<li>Graduate admissions application reviewer <span style="float:right;">2019 - Present</span></li>
					<li><a href="http://gtm.math.umd.edu/">Girls Talk Math</a> summer camp problem set reviewer <span style="float:right;">2021</span></li>
					<li>Graduate school application mentor <span style="float:right;">2020</span></li>
				</ul>
				<li><strong>Davidson College</strong></li>
				<ul>
					<li>Math & CS department student representative <span style="float:right;">2018 - 2019</span></li>
					<li>Davidson College ACM chapter co-founder <span style="float:right;">2018 - 2019</span></li>
				</ul>
			</ul>
		</div>

		<!-- ***************************************************************************** -->
		<!-- ***************************************************************************** -->
		<!-- ******************************** TEACHING *********************************** -->
		<!-- ***************************************************************************** -->
		<!-- ***************************************************************************** -->
		<div id="teaching"><a name="teaching"></a>
			<h2>Teaching</h2>
			<p>I greatly enjoy teaching since it's a combination of some of my favorite things: talking about computer science, introducing people to computer science, and learning. I would like to see more diverse groups of people become active in the computer science community, and I think teaching is an important step towards that. It's important to me that everyone has an equal opportunity to learn, so I try my best to be welcoming and unassuming about people's prior knowledge. I learned a lot about teaching from my time as an undergrad at Davidson, and I deeply agree with their approach to teaching.</p>
			<ul>
				<li><strong>New York University</strong></li>
				<ul>
					<li>Introduction to Programming and Problem Solving (CS-UY 1114 D) Instructor</a> <span style="float:right;">Spring 2025</span></li>
					<li><a href="https://docs.google.com/document/d/1dGa8Tc1b2M1zC4_Jw411EL2q0kDCXb7pI3OKSXx16qQ/edit?usp=sharing">Information Visualization Instructor (CS-GY 6313 B)</a> <span style="float:right;">Fall 2024</span></li>
				</ul>
				<li><strong>University of Maryland, College Park</strong></li>
				<ul>
					<li><a href="https://www.cs.umd.edu/class/spring2024/cmsc838C/">Advances in XR Head TA (CMSC838C)</a> <span style="float:right;">Spring 2024</span></li>
					<li>Game Programming TA (CMSC425) <span style="float:right;">Fall 2023</span></li>
					<li><a href="https://www.cs.umd.edu/class/spring2023/cmsc498F/">Advances in XR Head TA (CMSC838C)</a> <span style="float:right;">Spring 2023</span></li>
					<li><a href="https://www.cs.umd.edu/class/spring2022/cmsc498F/">Advances in XR TA (CMSC838C)</a> <span style="float:right;">Spring 2022</span></li>
					<li>Advanced Data Structures TA (CMSC420) <span style="float:right;">Fall 2021</span></li>
					<li>Bioinformatic Algorithms, Databases, and Tools TA (CMSC423) <span style="float:right;">Spring 2021</span></li>
					<li>Advanced Data Structures TA (CMSC420) <span style="float:right;">Fall 2020</span></li>
					<li>Game Programming TA (CMSC425) <span style="float:right;">Spring 2020</span></li>
					<li>Advanced Data Structures TA (CMSC420) <span style="float:right;">Fall 2019</span></li>
				</ul>
				<li><strong>Davidson College</strong></li>
				<ul>
					<li>Computer Science Tutor <span style="float:right;">2018 - 2019</span></li>
					<li>Computer Science Head TA <span style="float:right;">Spring 2019</span></li>
					<li>Computer Science Grader <span style="float:right;">2017 - 2018</span></li>
				</ul>
			</ul>
		</div>

		<!-- ***************************************************************************** -->
		<!-- ***************************************************************************** -->
		<!-- ******************************** FUN STUFF ********************************** -->
		<!-- ***************************************************************************** -->
		<!-- ***************************************************************************** -->
		<div id="fun_stuff"><a name="fun_stuff"></a>
			<h2>Fun Stuff</h2>
			<p>A collection of random bits of info about me or things I find interesting.</p>
			<ul>
				<li>While it's true that I'm a <a href="https://scholar.google.com/citations?user=KIUsT1cAAAAJ&amp;hl" target="_blank">published author</a>, I do not write <a href="http://www.niallwilliams.com/" target="_blank">novels</a>.<br /></li>
                <li>My typing speed is about 92 WPM.</li>
                  <li>I walked my dog during a hurricane once (nature calls!).</li>
                  <li>I have gone scuba diving with sharks in open water (no cage!).</li>
                  <li>I had a cast on my left arm and right leg at the same time for 6 weeks.</li>
                  <li>I won the only poker game I ever played. I no longer remember how to play poker.</li>
                  <li>Some of my favorite pictures of my cat:
                    <a href="img/tongue.jpg">Img 1<img src="" /></a>
                    <a href="img/balcony1.jpg">Img 2<img src="" /></a>
                    <a href="img/christmas.jpg">Img 3<img src="" /></a>
                    <a href="img/balcony2.jpg">Img 4<img src="" /></a>
                    <a href="img/balcony3.jpg">Img 5<img src="" /></a>
                    <a href="img/bed1.jpg">Img 6<img src="" /></a>
                    <a href="img/bed2.jpg">Img 7<img src="" /></a> 
                    <a href="img/cat_and_dog.jpg">Img 8<img src="" /></a>.</li>
                  <li>My undergrad thesis advisor and second reader made watching all episodes of Seinfeld a requirement to qualify for honors.</li>
                  <li>I once spent a summer helping newly-hatched sea turtles safely reach the ocean.</li>
                  <li><a href="https://www.csauthors.net/distance/paul-erdos/niall-williams" target="_blank">My Erd&#337;s Number is 4 (Me → Dinesh Manocha → Pankaj K. Agarwal → János Pach → Paul Erd&#337;s)</a><br></li>
                  <!-- <li><a href"https://academictree.org/math/distance.php?username=guest&sessionid=&refresh=1&search1=Carl++Gau%C3%9F+%28Gauss%29&pid1=7650&search2=Dinesh++Manocha&pid2=234766&includepd=1&Update=Find+Connection" target="_blank">Carl Gauss is my academic great-great-great-great-great-great-great-great-great-great-grandfather!</a> (That's 10 "greats"!)</li> -->
			</ul>

			<p>Useful resources:</p>
				<ul>
				<li><a href="http://tool.duruofei.com/abstract/" target="_blank">LaTeX abstract extractor</a></li>
				<li><a href="https://www.timeanddate.com/worldclock/converter.html?iso=20240315T110000&p1=3399" target="_blank">Time conversion for anywhere-on-earth.</a></li>
				<!-- <li><a href="https://casual-effects.com/markdeep/features.md.html" target="_blank">Markeep feature reference</a></li> -->
				<li><a href="http://niallw.github.io/misc/poster_templates.zip" target="_blank">Poster templates</a></li>
				<li><a href="https://www.sigaccess.org/welcome-to-sigaccess/resources/accessible-pdf-author-guide/" target="_blank">SIGACCESS guide to making your PDFs accessible to people with disabilities.</a></li>
				<li><a href="https://www.sigaccess.org/welcome-to-sigaccess/resources/accessible-presentation-guide/" target="_blank">SIGACCESS guide to making your presentations accessible to people with disabilities.</a></li>
				<li><a href="https://www.wigraph.org/spotlights/a-field-guide-to-undergraduate-research/" target="_blank">Article about how to get involved in research as an undergraduate student.</a></li>
				<li><a href="http://matt.might.net/articles/books-papers-materials-for-graduate-students/" target="_blank">Books for graduate students.</a></li>
				<li><a href="https://www.cc.gatech.edu/~turk/math_gr_new.html" target="_blank">Math for computer graphics.</a></li>
				<li><a href="http://web.engr.oregonstate.edu/~mjb/whirlwind/" target="_blank">Tour of computer graphics.</a></li>
				<li><a href="https://stats.idre.ucla.edu/other/mult-pkg/whatstat/" target="_blank">Statistical test cheat sheet (UCLA).</a></li>
				<li><a href="/img/stats_cheat_sheet.png" target="_blank">Statistical test cheat sheet (Andy Field book).</a></li>
				<li><a href="https://colorbrewer2.org/" target="_blank">Color scheme resource.</a></li>
				<li><a href="https://phdadvice.carrd.co/" target="_blank">Advice for CS PhD students.</a></li>
				<li><a href="https://matt.might.net/articles/academic-presentation-tips/" target="_blank">10 tips for academic talks.</a></li>
				<li><a href="https://ocw.mit.edu/resources/res-tll-005-how-to-speak-january-iap-2018/how-to-speak/" target="_blank">How to speak.</a></li>
				<li><a href="https://youtu.be/imEtTnQKt4M?t=153" target="_blank">How to title a paper, by Jitendra Malik</a></li>
				<li><a href="http://www.tkim.graphics/HOWTOTALK/HowToTalk.pdf" target="_blank">How to organize a presentation by Theodore Kim.</a></li>
				<li><a href="https://www.ogrants.org/" target="_blank">Accepted and rejected grant application examples.</a></li>
				<li><a href="https://www.nature.com/articles/d41586-019-03914-5" target="_blank">Secrets to writing a winning grant</a></li>
				<li><a href="https://www.bzarg.com/p/interview-tips-for-moving-up-to-leadership/#more-1190" target="_blank">What to know before going into an interview</a></li>
				<li><a href="https://deviparikh.medium.com/calendar-in-stead-of-to-do-lists-9ada86a512dd" target="_blank">How to organize your calendar</a></li>
				<li><a href="https://cs.uwaterloo.ca/~dmasson/tools/latin_square/" target="_blank">Latin square calculator</a></li>
				<li><a href="https://parentheticallyspeaking.org/articles/us-cs-phd-faq/" target="_blank">USA CS PHD FAQ</a></li>
				<li><a href="https://www.silviasellan.com/gender_question.html" target="_blank">Information on asking about name/gender on data-collection forms.</a></li>
				<li><a href="https://ubadahsabbagh.com/guide-to-postdoc.php" target="_blank">Guide to postdoc</a></li>
				<li><a href="https://flamingtempura.github.io/bibtex-tidy/" target="_blank">Bibtex cleaning tool</a></li>
				<li><a href="https://niallw.github.io/pdfs/gradschooltalk.pdf" target="_blank">Applying to Ph.D. Programs in Computer Science</a></li>
				<li><a href="https://niallw.github.io/pdfs/DAGAP.pdf" target="_blank">Demystifying the American Graduate Admissions Process</a></li>
				<li><a href="http://nifty.stanford.edu/" target="_blank">Nifty assignment ideas</a></li>
				<li><a href="https://scratchapixel.com/" target="_blank">Online "course" for learning graphics programming.</a></li>
				<li><a href="https://www.happyscribe.com/" target="_blank">Automatically generate and add subtitles to a video.</a></li>
				<li><a href="https://elvers.us/perception/visualAngle/" target="_blank">Visual Angle (Field of View) Calculator</a></li>
				<li><a href="http://backreaction.blogspot.com/2018/09/im-now-older-than-my-father-has-ever.html?m=1" target="_blank">Sabine Hossenfelder: I'm now older than my father has ever been</a></li>
				<li><a href="http://paulgraham.com/greatwork.html" target="_blank">Paul Graham: How to do great work</a></li>
				<li><a href="https://crystaljjlee.com/blog/how-much-have-i-been-paid-in-academic-or-ac-adjacent-jobs/" target="_blank">Crystal Lee: Salary + negotiation notes for academia</a></li>
				<li><a href="https://gamemath.com" target="_blank">Math for 3D graphics.</a></li>
				<li><a href="niallw.github.io/unit_circle" target="_blank">Unit Circle angle visualizer</a></li>
				<li><a href="https://matthias-research.github.io/pages/tenMinutePhysics/index.html" target="_blank">10-minute Physics for Computer Graphics</a></li>
				<li><a href="pdfs/samaha_cheapchinrest.pdf" target="_blank">DIY build your own chinrest #1</a></li>
				<li><a href="pdfs/How_to_build_the_chinrest.pdf" target="_blank">DIY build your own chinrest #2</a></li>
				<li><a href="https://csguides.github.io/grad-job-guide/" target="_blank">CS Academic Job Guide</a></li>
				<li><a href="https://displayhdr.org/performance-criteria/#ctsoverview" target="_blank">VESA standards for display measurement/calibration</a></li>
				<li><a href="vision_values.html" target="_blank">Brian Wandell's Useful Vision Values</a></li>
				<li><a href="https://docs.google.com/document/d/1Kc4AUlhtgrO8_oDrs9IqO40OEMe7HQM_ShQHyLNwlBQ/edit?tab=t.0" target="_blank">Dr. Svetlana Yarosh's PhD Guide</a></li>
				<li><a href="https://docs.google.com/document/d/1YiiDsfpiolpXjUTj8xWrQwQQUzqrfqT9bocOpaYDrtI/edit?tab=t.0" target="_blank">Dr. Jon Froehlich's Lab Handbook</a></li>
				<!-- <li><a href="LINK" target="_blank">DESCRIPTION</a></li> -->
				</ul>

				<p>Fun reads/cool things:</p>
				<ul>
					<li><a href="http://tomforsyth1000.github.io/blog.wiki.html#%5B%5BVR%20optics%20and%20why%20IPD%20means%20too%20many%20things%5D%5D" target="_blank">Tom Forsyth on IPD</a></li>
					<li><a href="http://paulgraham.com/genius.html" target="_blank">The bus ticket theory of genius</a></li>
					<li><a href="https://helloenjoy.itch.io/lights" target="_blank">Lights</a></li>
					<li><a href="https://www.emojisearch.app/" target="_blank">Emoji search</a></li>
					<!-- <li><a href="LINK" target="_blank">DESCRIPTION</a></li> -->
				</ul>
		</div>

		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
			<tr>
			  <td style="padding:0px">
				<br>
				<p style="text-align:right;font-size:small;">
				  <a href="https://people.cs.clemson.edu/~sjoerg/">Website format copied from Sophie J&ouml;rg.</a>
				  <br>
				</p>
			  </td>
			</tr>
		</tbody></table>

		<div id="footer">
		</div>
	</div>
</body>

</html>
